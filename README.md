# 100-Days-Of-ML-Code-Challenge
## Day 1
I read my first research paper, it was a paper written by Andrew Ng and Michael Jordan in 2002, it talked about the difference between discriminative and generative classifiers, it specifically compared between Naive Bayes and Logistic Regression. It was really hard for me to understand, but it felt good trying to.
## Day 2
Today, I started learning about Machine learning theory, it requires so many knowledge and background, it needs someone who understands algorithms, information theory, and a great deal of math, I was afraid of it at first, but I took my time to understand a few things and it went well. I learned about sample complexity, which was a little hard to grasp but it explains important things regarding machine learning in general, which helped me look at the bigger picture for a while.
## Day 3
Today, I started learning about NLP. I joined the Deeplearning.ai specialization of NLP, it seemed easy to understand. I also opened a tutorial provided by Freecodecamp and edureka to start learning about basic NLP concepts such as Lemmetization and Stemming.
## Day 4
Today, I followed along a tutorial that build an RNN LSTM model to predict Gamestop stock prices, it seemed cool, I installed tensorflow for the first time. I also found out about this cool AI auto completion plugin that works on jupyter lab and python, it's called kite. I read a little bit of the book "Hands-on Machine Learning using Scikit learn, Keras, and tensorflow, it's amazing that I understand things, since I was nervous about reading my first technical book.
